# -*- coding: utf-8 -*-
"""computer vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iYEqqfoYEVpJX39Qrp8nwZ1NCQ2rB_RX
"""

pip install tensorflow opencv-python numpy matplotlib scikit-learn

import os
import cv2
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# -------------------------------
# Load Dataset
# -------------------------------
data = []
labels = []

DATASET_PATH = "dataset"
CATEGORIES = ["no", "yes"]

for category in CATEGORIES:
    folder_path = os.path.join(DATASET_PATH, category)
    label = CATEGORIES.index(category)

    for img_name in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_name)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (128, 128))
        img = img / 255.0

        data.append(img)
        labels.append(label)

data = np.array(data)
labels = to_categorical(labels, 2)

# -------------------------------
# Train-Test Split
# -------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    data, labels, test_size=0.2, random_state=42
)

# -------------------------------
# CNN Model
# -------------------------------
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(2, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# -------------------------------
# Training
# -------------------------------
model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# -------------------------------
# Save Model
# -------------------------------
model.save("model.h5")
print("Model saved successfully")

import os
import numpy as np
import cv2

# Define the base directory and categories as in your model code
DATASET_PATH = "dataset"
CATEGORIES = ["no", "yes"]

# Create the main dataset directory if it doesn't exist
if not os.path.exists(DATASET_PATH):
    os.makedirs(DATASET_PATH)
    print(f"Created directory: {DATASET_PATH}")

# Create subdirectories for each category
for category in CATEGORIES:
    category_path = os.path.join(DATASET_PATH, category)
    if not os.path.exists(category_path):
        os.makedirs(category_path)
        print(f"Created directory: {category_path}")

print("Dataset directory structure created successfully.")

# Create some dummy image files for testing
# In a real scenario, you would place your actual MRI images here.

# Example: create 5 dummy images for 'no' category
for i in range(5):
    dummy_image_path = os.path.join(DATASET_PATH, 'no', f'dummy_no_{i}.jpg')
    # Create a blank white image (128x128, 3 channels)
    dummy_img = np.ones((128, 128, 3), dtype=np.uint8) * 255
    cv2.imwrite(dummy_image_path, dummy_img)
    print(f"Created dummy image: {dummy_image_path}")

# Example: create 5 dummy images for 'yes' category
for i in range(5):
    dummy_image_path = os.path.join(DATASET_PATH, 'yes', f'dummy_yes_{i}.jpg')
    # Create a blank black image (128x128, 3 channels)
    dummy_img = np.zeros((128, 128, 3), dtype=np.uint8)
    cv2.imwrite(dummy_image_path, dummy_img)
    print(f"Created dummy image: {dummy_image_path}")

print("Dummy images created for testing.")

"""After running the cells above, you will have a `dataset` directory with `no` and `yes` subfolders, each containing 5 dummy `.jpg` files. You should replace these dummy files with your actual brain MRI images for training your model. Make sure your MRI images are in a compatible format (e.g., JPEG, PNG)."""

import cv2
import numpy as np
from tensorflow.keras.models import load_model

model = load_model("model.h5")

# Change the img_path to one of the dummy images created earlier for testing
# For example, let's use a dummy 'no' tumor image:
img_path = "dataset/no/dummy_no_0.jpg"  # MRI image to test
# Or, to test a 'yes' tumor image:
# img_path = "dataset/yes/dummy_yes_0.jpg"

img = cv2.imread(img_path)

# Check if the image was loaded successfully
if img is None:
    print(f"Error: Could not load image from {img_path}")
else:
    img = cv2.resize(img, (128,128))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)

    prediction = model.predict(img)
    class_index = np.argmax(prediction)

    if class_index == 1:
        print("Tumor Detected")
    else:
        print("No Tumor Detected")